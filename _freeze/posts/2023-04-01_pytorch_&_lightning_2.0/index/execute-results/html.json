{
  "hash": "e701049e718ab7378da5d2f4579fd433",
  "result": {
    "markdown": "---\ntitle: \"Riding the Waves - PyTorch and Lightning 2.0\"\ndescription: \"In this post, I will be talking about the new release by PyTorch and PyTorch Lightning. Also testing the potential of the new updates.\" \nauthor: \"John Pinto\"\ndate: \"2023-04-01\"\ncategories: [\"PyTorch\", \"Lightning\", \"Fabric\", \"AI\", \"Video Classification\"]\nimage: \"featured.png\"\ntoc: true\npage-layout: full\ncode-fold: true\nnotebook-links: inline\n---\n\n```{=html}\n<style>\n.quarto-figure-center > figure {\n  text-align: center;\n}\n</style>\n```\n\n![](featured.png){fig-align=\"center\"}\n\n# Quick Facts on PyTorch and Lightning 2.0 Release\n\nPyTorch and PyTorch Lightning (2.0) were released on 15 March, 2023.\n\n**PyTorch**: The main focus being the improvement in the speed, even the release article title says it\n\n> \"PyTorch 2.0: Our next generation release that is faster, more Pythonic and Dynamic as ever\"\n\nyou can read the article over [here](https://pytorch.org/blog/pytorch-2.0-release/).\n\nThis speed that they mention comes with just a single line of code. After you have created your model you just use this code and the code modifies your model to perform at it's best level.\n\n``` python\ntorch.compile()\n```\n\nThey have even mentioned the details while testing the new functionality and how the `torch.compile()` can improve the speed of the models from different sources \\[[HuggingFace](https://github.com/huggingface/transformers), [TIMM](https://github.com/rwightman/pytorch-image-models) and [TorchBench](https://github.com/pytorch/benchmark/)\\].\n\nTo run this amazing compiled model, PyTorch introduces new technologies - TorchDynamo, AOTAutograd, PrimTorch and TorchInductor. All of this new technologies are working in a flow and they are broken down in three phases - Graph Acquisition, Graph Lowering and Graph Compilation. You can check all of this over [here](https://pytorch.org/get-started/pytorch-2.0/), they have explained complex system in easy to understand way.\n\n::: callout-tip\nRead the above linked article, especially the section on [technology overview](https://pytorch.org/get-started/pytorch-2.0/#technology-overview), this will help you understand the hyper-parameters workings within the torch.compile().\n:::\n\n**PyTorch Lightning** on the other hand was just kind of following PyTorch, they have just mentioned that lightning supports PyTorch 2.0 with backward compatibility and this itself makes it a mature release. But what makes lightning amazing in this release is not the support but the introduction to a new library \"[Lightning Fabric](https://lightning.ai/pages/open-source/fabric/)\".\n\n![The space where \"Lightning Fabric\" occupies.](images/fabric.png){fig-align=\"center\"}\n\nPyTorch Lightning has a history for converting the vanilla style of PyTorch code by removing all the boilerplate code. This way it helps in setting up the model training much faster but at the cost of higher complexity when you try to control somethings that you can't. Now, that Fabric is come into the picture this changes the way you are going to train your model. They have basically given control on some of the complex task like accelerators, distributed strategies, and mixed precision, while still retaining full control on your training loop.\n\n## Caveats Part of the Release\n\nPyTorch and PyTorch Lightning 2.0 are the stable release but there are some information that needs attention.\n\n1.  **Hardware**: This speed up performance that the PyTorch team speaks of are based on specific hardware, broadly they have mentioned that NVIDIA Volta and Ampere server class GPUs are capable to produce decent results. So desktop GPUs will need to wait for later releases.\n2.  **Model Saving/Exporting**: Right now the compile model can only be saved using the `model.state_dict()` method. You won't me able to save the object of the model, which returns an error if you try to. You can read the [serialization](https://pytorch.org/get-started/pytorch-2.0/#serialization) part of the article that I have mentioned above. Along with the save part, team will also introduce `torch.export()` mode in the later release.\n\n# Enough Theory, Time to Experiment...\n\nBefore I start showing my code and results, let me brief you about it. Many website were already showing the methodology and results of the PyTorch 2.0 on different models, you can check the blog article of [Weights and Biases](https://api.wandb.ai/links/gladiator/d0o6cxp0) that show how they implemented and test the new features.\n\nI wanted to try something different so I choose to implement and test it on a video classification problem rather than a Image Classification or NLP problem. For my Video Classification problem I went with the [HMDB51 dataset](https://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database). Now, the next step was selecting the hardware, majority of the website have shown that they were using Nvidia A100 GPU, even PyTorch themselves have shown the results based on this hardware and have recommended GPU similar to this type off. For me the only available Ampere GPU was Nvidia **A4000 (CUDA: 8.6)** and as a reference I even used a **Tesla T4 (CUDA: 7.5)**.\n\n::: callout-note\nThere's a reason why PyTorch compile mode needs Volta and Ampere GPUs, because the minimum CUDA compute capability needs to be more than 8.0. You can check your hardware compute capability on the [Nvidia website](https://developer.nvidia.com/cuda-gpus).\n:::\n\n### Methodology\n\nThe main motive of this testing is to compare the benchmark of the PyTorch 1.13 (Eager Mode) and PyTorch 2.0 (Compile Mode).\n\nThere are three Phases of testing that I have conducted:\n\n1.  PyTorch Test\n2.  PyTorch Lightning Test\n3.  Lightning Fabric Test\n\n### Dataset, Dataloaders and Model Details\n\n-   Dataset contains 51 Classes, I have used only **20 classes** for all the experiment.\n\n-   The dataset contained fixed sequencce length of **16 frames**.\n\n-   Total Training Sample: **1898** and Total Validation/Testing Samples: **632**.\n\n-   Batch size: **16** and number of workers was set to max of CPU cores: **8**.\n\n-   [MVit V2 Small](https://arxiv.org/abs/2104.11227) Model was used for all the experiments from [torchvision](https://pytorch.org/vision/main/models/generated/torchvision.models.video.mvit_v2_s.html).\n\n-   **Cross entropy** was used as a loss function and **Adam optimizer** was used for optimizing the model at a default learning rate of **1e-3.**\n\n-   In all the experiments the model was trained for **3 epochs**.\n\nYou can check my [Jupyter notebook](https://github.com/JohnPPinto/HMDB51_human_motion_recognition_pytorch/blob/main/HMDB51_human_action_recognition_pytorch.ipynb){target=\"_blank\"} for complete understanding of the dataset preprocessing, Dataloaders and model details.\n\n### Phase 1 - PyTorch Implementation\n\nFor this phase, I have used the basic training pipeline code used in PyTorch.\n\n**Defining Code Structure:**\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\ndef train_step(model, dataloader, loss_fn, optimizer, device, num_classes):\n    \"\"\"\n    Trains a pytorch model by going into train mode and applying forward pass,\n    loss calculation and optimizer step.\n    \n    Parameters:\n        model: A pytorch model for training.\n        dataloader: A pytorch dataloader for training.\n        loss_fn: A pytorch loss to calculate the model's prediction loss.\n        optimizer: A pytorch optimizer to minimize the loss function.\n        device: A torch device to allocate tensors on 'cpu' or 'cuda'.\n        num_classes: A integer that indicates total number of classes in the dataset.\n        \n    Returns: A tuple of training loss and training accuracy.\n        \n    \"\"\"\n    # Model on training mode\n    model.train()\n    \n    # Setting train loss and accuracy \n    train_loss = 0\n    train_acc = torchmetrics.Accuracy(task='multiclass', \n                                      num_classes=num_classes).to(device)\n    \n    # Looping the dataloaders\n    for batch, (X, y) in tqdm(enumerate(dataloader), \n                              desc='Model Training', \n                              total=len(dataloader), \n                              unit='batch'):\n        X, y = X.to(device), y.to(device)\n        \n        # 5 step to train a model\n        y_pred = model(X) # 1. Forward pass\n        loss = loss_fn(y_pred, y) # 2. Calculate loss\n        train_loss += loss.item() \n        optimizer.zero_grad() # 3. Initiate optimizer\n        loss.backward() # 4. Backward pass\n        optimizer.step() # 5. Updating the model parameters\n        \n        # Calculating the training accuracy\n        y_pred_labels = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n        train_acc.update(y_pred_labels, y)\n    \n    # Averaging the loss and accuracy\n    train_loss = train_loss / len(dataloader)\n    train_acc = train_acc.compute()\n    return train_loss, train_acc\n\ndef test_step(model, dataloader, loss_fn, device, num_classes):\n    \"\"\"\n    Test a pytorch model by going into eval mode and applying forward pass,\n    and loss calculation.\n    \n    Parameters:\n        model: A pytorch model for testing.\n        dataloader: A pytorch dataloader for testing.\n        loss_fn: A pytorch loss to calculate the model's prediction loss.\n        device: A torch device to allocate tensors on 'cpu' or 'cuda'.\n        num_classes: A integer that indicates total number of classes in the dataset.\n        \n    Returns: A tuple of testing loss and testing accuracy.\n    \"\"\"\n    # Model on evaluation mode\n    model.eval()\n    \n    # Setting train loss and accuracy \n    test_loss = 0\n    test_acc = torchmetrics.Accuracy(task='multiclass', \n                                     num_classes=num_classes).to(device)\n    \n    # Using inference mode\n    with torch.no_grad():\n        # Looping the dataloaders\n        for batch, (X, y) in tqdm(enumerate(dataloader), \n                                  desc='Model Evaluation', \n                                  total=len(dataloader), \n                                  unit='batch'):\n            X, y = X.to(device), y.to(device)\n            \n            # Forward pass\n            y_pred = model(X)\n            \n            # Calculate loss\n            loss = loss_fn(y_pred, y)\n            test_loss += loss.item()\n            \n            # Calculate accuracy\n            y_pred_labels = y_pred.argmax(dim=1)\n            test_acc.update(y_pred_labels, y)\n    \n    # Averaging the loss and accuracy\n    test_loss = test_loss / len(dataloader)\n    test_acc = test_acc.compute()\n    return test_loss, test_acc\n\ndef model_train(epochs, model, train_dataloader, test_dataloader, optimizer, loss_fn, device, num_classes):\n    \"\"\"\n    Trains a pytorch model for a certain number of epochs going through the model training \n    and testing stage, and accumalating the loss, accuracy, and training and testing time.\n    \n    Parameters:\n        epochs: A integer to run the training and testing stage. \n        model: A pytorch model for training and testing.\n        train_dataloader: A pytorch dataloader for training.\n        test_dataloader: A pytorch dataloader for testing.\n        loss_fn: A pytorch loss to calculate the model's prediction loss.\n        optimizer: A pytorch optimizer to minimize the loss function.\n        device: A torch device to allocate tensors on 'cpu' or 'cuda'.\n        num_classes: A integer that indicates total number of classes in the dataset.\n        \n    Returns: A tuple of accumaleted results in dict and total training time in float datatype.\n    \"\"\"\n    # Create empty result\n    results = {'train_loss': [],\n               'train_acc': [],\n               'test_loss': [],\n               'test_acc': [],\n               'train_epoch_time(min)': [],\n               'test_epoch_time(min)': []}\n    \n    # Loop through training and testing steps\n    model_train_start_time = timer()\n    for epoch in tqdm(range(epochs), desc=f'Training and Evaluation for {epochs} Epochs', unit='epochs'):\n        # Training the model and timing it.\n        train_epoch_start_time = timer()\n        train_loss, train_acc = train_step(model=model, \n                                           dataloader=train_dataloader, \n                                           loss_fn=loss_fn, \n                                           optimizer=optimizer, \n                                           device=device, \n                                           num_classes=num_classes)\n        train_epoch_stop_time = timer()\n        train_epoch_time = (train_epoch_stop_time - train_epoch_start_time)/60\n        \n        # Testing the model and timing it\n        test_epoch_start_time = timer()\n        test_loss, test_acc = test_step(model=model,\n                                        dataloader=test_dataloader,\n                                        loss_fn=loss_fn,\n                                        device=device,\n                                        num_classes=num_classes)\n        test_epoch_stop_time = timer()\n        test_epoch_time = (test_epoch_stop_time - test_epoch_start_time)/60\n        \n        # Print the model result\n        print(f'Epoch: [{epoch+1}/{epochs}] | train_loss: {train_loss:.4f} | train_acc: {train_acc:.4f} | train_time: {train_epoch_time:.4f} min | '\n              f'test loss: {test_loss:.4f} | test_acc: {test_acc:.4f} | test_time: {test_epoch_time:.4f} min')\n        \n        # Saving the results\n        results['train_loss'].append(train_loss)\n        results['train_acc'].append(train_acc.detach().cpu().item())\n        results['test_loss'].append(test_loss)\n        results['test_acc'].append(test_acc.detach().cpu().item())\n        results['train_epoch_time(min)'].append(train_epoch_time)\n        results['test_epoch_time(min)'].append(test_epoch_time)\n        \n    # Calculating total model training time\n    model_train_end_time = timer()\n    total_train_time = (model_train_end_time - model_train_start_time)/60\n    print(f'\\nTotal Model Training Time: {total_train_time:.4f} min')\n    return results, total_train_time\n```\n:::\n\n\n**Running the code:**\n\n<details>\n<summary>Code</summary>\n``` python\nset_seed(42)\n\n# Initializing the model and dataloaders\nmodel, transforms = create_model(num_classes=len(dataset.classes), device=device)\nmodel.to(device)\ntrain_dataloader = create_dataloaders(dataset=train_dataset, batch=BATCH_SIZE, shuffle=True, workers=WORKERS)\ntest_dataloader = create_dataloaders(dataset=test_dataset, batch=BATCH_SIZE, shuffle=False, workers=WORKERS)\n\n# Intializing loss and optimizer\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(params=model.parameters(), lr=0.0001)\n\n# Setting up compiled model(Introduced in PyTorch 2.0.0)\nmodel = torch.compile(model, mode='default') # Only used it durning Exp 2.\n\n# Training the model using the function\nNUM_EPOCHS = 3\nexp2_results, exp2_total_train_time = model_train(epochs=NUM_EPOCHS,\n                                                  model=model,\n                                                  train_dataloader=train_dataloader,\n                                                  test_dataloader=test_dataloader,\n                                                  optimizer=optimizer,\n                                                  loss_fn=loss_fn,\n                                                  device=device,\n                                                  num_classes=len(dataset.classes))\n```\n</details>\n\n<!-- 12A0366C:notebooks/blog_figures.ipynb#fig-pytorch-exp |  | echo:false,warning:false,asis:true,eval:false -->\n\nAs you can see the loss and accuracy are quite similar for both the experiments. The result needs to be same because we do not change the model and the epoch is also same for both. This is good for the new features that it does not make any changes with the model rather a container is created and model is fitted within that container.\n\nThe PyTorch team has mentioned that the major changes you will see is with speed, for this to happen all the processing is been done in the initial epoch later there should be a increase in speed, but in my case the eager is doing much better than the compile mode. This might be due to the hardware that I am using the A4000 GPU.\n\n### Phase 2 - PyTorch Lightning Implementation\n\nThe training pipeline is similar as before but the structure is defined as per the lightning methodology.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nclass PyLightHMDB51():\n    \"\"\"\n    A Lightning Module containing Model training and validation step.\n    Parameters: \n        model: A PyTorch Model.\n        loss_fn: A PyTorch loss function.\n        optimizer: A Pytorch Optimizer.\n        num_classes: A integer for total number of classes in the dataset.\n    \"\"\"\n    def __init__(self, model, loss_fn, optimizer, num_classes):\n        super().__init__()\n        self.model = model\n        self.loss_fn = loss_fn\n        self.optimizer = optimizer\n        self.num_classes = num_classes\n        self.train_acc = torchmetrics.Accuracy(task='multiclass', \n                                               num_classes=self.num_classes)\n        self.test_acc = torchmetrics.Accuracy(task='multiclass', \n                                              num_classes=self.num_classes)\n        \n    def forward(self, x):\n        return self.model(x)\n    \n    def training_step(self, train_batch, batch_idx):\n        X, y = train_batch\n        y_preds = self.forward(X)\n        loss = self.loss_fn(y_preds, y)\n        self.log('train_loss', loss, prog_bar=True, on_step=False, on_epoch=True)\n        y_pred_labels = torch.argmax(torch.softmax(y_preds, dim=1), dim=1)\n        self.train_acc.update(y_pred_labels, y)\n        self.log('train_acc', self.train_acc, prog_bar=True, on_step=False, on_epoch=True)\n        return loss\n    \n    def validation_step(self, val_batch, batch_idx):\n        X, y = val_batch\n        y_preds = self.forward(X)\n        loss = self.loss_fn(y_preds, y)\n        self.log('test_loss', loss, prog_bar=True, on_step=False, on_epoch=True)\n        y_pred_labels = torch.argmax(torch.softmax(y_preds, dim=1), dim=1)\n        self.test_acc.update(y_pred_labels, y)\n        self.log('test_acc', self.test_acc, prog_bar=True, on_step=False, on_epoch=True)\n    \n    def configure_optimizers(self):\n        optimizers = self.optimizer\n        return optimizers\n```\n:::\n\n\n/\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}